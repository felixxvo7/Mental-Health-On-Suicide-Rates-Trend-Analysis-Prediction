numerator_norm <-  abs(norm_var) *dt(norm_var,df = 3)
denominator_norm <- dnorm(norm_var)
importance_weights_norm <- numerator_norm / denominator_norm
theta_estimate_is_norm <- mean(importance_weights_norm)
theta_estimate_is_norm
knitr::opts_chunk$set(echo = TRUE)
library(mvtnorm)
covmat <- matrix(c(1, 0.2, 0.2, 1), ncol = 2)
covmat
rmvnorm(3, mean = c(0, 0), sigma = covmat)
install.packages("openintro")
install.packages("GGally")
install.packages("FSA")
knitr::opts_chunk$set(echo = TRUE)
## Type your answer here ##
iris
## Type your answer here ##
iris_data <- iris
View(iris_data)
library(tidyverse)
## Type your answer here ##
setosa_iris_data <- iris_data %>%
filter(Species = "setosa" )%>%
plot(Petal.length,Petal.width)
library(tidyverse)
## Type your answer here ##
setosa_iris_data <- iris_data %>%
filter(Species == "setosa" )%>%
plot(Petal.length,Petal.width)
library(tidyverse)
## Type your answer here ##
setosa_iris_data <- iris_data %>%
filter(Species %in% "setosa" )%>%
plot(Petal.Length,Petal.Width)
library(tidyverse)
## Type your answer here ##
setosa_iris_data <- iris_data %>%
filter(Species %in% "setosa" )
plot(setosa_iris_data$Petal.Length,setosa_iris_data$Petal.Width)
library(tidyverse)
## Type your answer here ##
setosa_iris_data <- iris_data %>%
filter(Species %in% "setosa" )
setosa_iris_data
plot(setosa_iris_data$Petal.Length,setosa_iris_data$Petal.Width)
library(tidyverse)
## Type your answer here ##
setosa_iris_data <- iris_data %>%
filter(Species %in% "setosa" )
plot(setosa_iris_data$Petal.Length,setosa_iris_data$Petal.Width)
library(tidyverse)
## Type your answer here ##
setosa_iris_data <- iris_data %>%
filter(Species %in% "setosa" )
plot(setosa_iris_data$Sepal.Length,setosa_iris_data$Sepal.Width)
## Type your answer here ##
cor(setosa_iris_data$Sepal.Length,setosa_iris_data$Sepal.Width)
knitr::opts_chunk$set(echo = TRUE,tidy.opts=list(width.cutoff=90), tidy=TRUE, warning = FALSE,message = FALSE)
cor(mtcars$mpg,mtcars$disp)
## Type your answer here ##
dunnTest(Species,data=iris_data,method = median())
## Type your answer here ##
library(infer)
library(FSA)
dunnTest(Species ~ Sepal.Length, data = iris_data, method = "median")
## Type your answer here ##
library(infer)
library(FSA)
dunnTest(Sepal.Length ~ Species  , data = iris_data, method = "median")
## Type your answer here ##
library(infer)
library(FSA)
dunnTest(Sepal.Length ~ Species  , data = iris_data, method = "bonferroni")
## Type your answer here ##
library(infer)
library(FSA)
kruskal.test(Sepal.Length ~ Species  , data = iris_data)
## Type your answer here ##
dunnTest(Sepal.Length ~ Species  , data = iris_data, method = "bonferroni")
library(infer)
library(FSA)
kruskal.test(Sepal.Length ~ Species  , data = iris_data)
## Type your answer here ##
mtcars$Species <- factor(mtcars$Species)
## Type your answer here ##
iris_data$Species <- factor(mtcars$Species)
## Type your answer here ##
iris_data$Species <- ggplot(iris_data, aes(x = Sepal.Length, fill = Species)) +
geom_density(alpha = 0.5) +
facet_wrap(~ Species) +
labs(title = "Density Plots of MPG by Cylinder")
ggplot(iris_data, aes(x=Sepal.Length, y=Species))+
geom_boxplot()+
geom_point()+
geom_jitter(height=0.25)
View(setosa_iris_data)
## Type your answer here ##
setosa_iris_data <- iris_data %>%
filter(!Species %in% "versicolor" )
## Type your answer here ##
filtered_iris_data <- iris_data %>%
filter(!Species %in% "versicolor" )
filtered_iris_data
## Type your answer here ##
filtered_iris_data <- iris_data %>%
filter(!Species %in% "versicolor" )
kruskal.test(Sepal.Length ~ Species  , data = filtered_iris_data)
library(tidyverse)
## Type your answer here ##
setosa_iris_data <- iris_data %>%
filter(Species == "setosa")
ggplot(setosa_iris_data, aes(x = Sepal.Length, y = Sepal.Width)) +
geom_point() +
labs(title = "Scatter Plot of Sepal Length vs Sepal Width for Setosa",
x = "Sepal Length", y = "Sepal Width")
library(tidyverse)
## Type your answer here ##
setosa_iris_data <- iris_data %>%
filter(Species == "setosa")
ggplot(setosa_iris_data, aes(x = Sepal.Length, y = Sepal.Width)) +
geom_point() +
labs(title = "Scatter Plot",
x = "Sepal Length", y = "Sepal Width")
library(tidyverse)
## Type your answer here ##
setosa_iris_data <- iris_data %>%
filter(Species == "setosa")
ggplot(setosa_iris_data, aes(x = Sepal.Length, y = Sepal.Width)) +
geom_point() +
labs(title = "Scatter Plot Length vs Width for Setosa",
x = "Sepal Length", y = "Sepal Width")
ggplot(iris_data, aes(x = Species, y = Sepal.Length)) +
geom_boxplot(fill = "skyblue", color = "black") +
labs(title = "Box Plot of Sepal Length by Species",
x = "Species", y = "Sepal Length")
ggplot(iris_data, aes(x = Species, y = Sepal.Length)) +
geom_boxplot(fill = "skyblue", color = "black") +
labs(x = "Species", y = "Sepal Length")
ggplot(iris_data, aes(x=Sepal.Length, y=Species))+
geom_boxplot()+
geom_point()+
geom_jitter(height=0.25)
ggplot(iris_data, aes(x=Sepal.Length, y=Species))+
geom_boxplot()+
geom_point()+
geom_jitter(height=0.25)+
labs(title = "Box Plot of Sepal Length by Species",
x = "Species", y = "Sepal Length")
ggplot(iris_data, aes(x=Sepal.Length, y=Species))+
geom_boxplot()+
geom_point()+
geom_jitter(height=0.25)+
labs(x = "Species", y = "Sepal Length")
library(infer)
library(FSA)
kruskal.test(Sepal.Length ~ Species, data = iris_data)
## Type your answer here ##
# Filter data for setosa and virginica
setosa <- subset(iris, Species == "setosa")$Sepal.Length
virginica <- subset(iris, Species == "virginica")$Sepal.Length
# Perform Wilcoxon rank-sum test
wilcox.test(setosa, virginica)
## Type your answer here ##
filtered_iris_data <- iris_data %>%
filter(!Species %in% "versicolor" )
kruskal.test(Sepal.Length ~ Species  , data = filtered_iris_data)
# Filter data for setosa and virginica
setosa <- subset(iris, Species == "setosa")$Sepal.Length
virginica <- subset(iris, Species == "virginica")$Sepal.Length
# Perform Wilcoxon rank-sum test
wilcox.test(setosa, virginica)
## Type your answer here ##
filtered_iris_data <- iris_data %>%
filter(!Species %in% "versicolor" )
kruskal.test(Sepal.Length ~ Species  , data = wilcox.test(Sepal.Length ~ Species)
library(dplyr)
setosa <- iris %>% filter(Species == "setosa") %>% pull(Sepal.Length)
virginica <- iris %>% filter(Species == "virginica") %>% pull(Sepal.Length)
wilcox.test(setosa, virginica)
library(dplyr)
setosa <- iris %>% filter(Species == "setosa")
virginica <- iris %>% filter(Species == "virginica")
wilcox.test(setosa$Sepal.Length, virginica$Sepal.Length)
install.packages("colorspace")
knitr::opts_chunk$set(echo = TRUE,tidy.opts=list(width.cutoff=90), tidy=TRUE, warning = FALSE,message = FALSE)
network <- read.csv("/Users/ruwaniherath/Dropbox/Teaching/Data 2010_Winter 2025/Labs/Network.csv")
knitr::opts_chunk$set(echo = TRUE)
update_elo <- function(R_old, R_opp, S_e , K ,C) {
Mu_e = 1 / (1 + exp(C*(R_old - R_opp))) # Expected score
R_new = R_old + K * (S_e - Mu_e)        # New rating
return(R_new)
}
# Initial ratings
R_old <- 2735  # Player A
R_opp <- 2463  # Player B
# Actual scores (Player A wins)
S_A <- 1
S_B <- 0
K=32 #K = 32 is common in chess.
C=5
R_new_A <- update_elo(R_old,R_opp,S_A, K,C)
R_new_B <- update_elo(R_opp,R_old,S_B,K,C)
# Display new ratings
cat("New rating for Player A:", round(R_new_A, 2), "\n")
cat("New rating for Player B:", round(R_new_B, 2), "\n")
update_elo <- function(R_old, R_opp, S_e , K ,C) {
Mu_e = 1 / (1 + exp(C*(R_old - R_opp))) # Expected score
R_new = R_old + K * (S_e - Mu_e)        # New rating
return(R_new)
}
knitr::opts_chunk$set(echo = TRUE,tidy.opts=list(width.cutoff=90), tidy=TRUE, warning = FALSE,message = FALSE)
## Type your answer here ##
library(tidyverse)
library(MASS)
data<- Boston %>% dplyr::select('crim','age','medv')
data
normalized_data<- transform(data,method='zscore')
normalized_data
library(liver)
install.packages("liver")
library(liver)
normalized_data<- transform(data,method='zscore')
normalized_data
zscore<- function(x) {
(x - mean(x)) / sd(x)
}
normalized_data <- as.data.frame(lapply(data, zscore))
head(normalized_data,3)
zscore<- function(x) {
(x - mean(x)) / sd(x)
}
normalized_data <- as.data.frame(lapply(data, zscore))
head(normalized_data,3)
zscore<- function(x) {
(x - mean(x)) / sd(x)
}
normalized_data <- as.data.frame(lapply(data, zscore))
normalized_data
normalized_data <- as.data.frame(lapply(data, zscore))
zscore<- function(x) {
(x - mean(x)) / sd(x)
}
normalized_data <- as.data.frame(lapply(data, zscore))
head(normalized_data,3)
zscore<- function(x) {
(x - mean(x)) / sd(x)
}
normalized_data <- as.data.frame(lapply(data, zscore))
head(normalized_data,5)
head(normalized_data)
zscore<- function(x) {
(x - mean(x)) / sd(x)
}
normalized_data <- as.data.frame(lapply(data, zscore))
head(normalized_data)
score<- function(crim,age,medv) {
0.1*crim+ 0.4*age + 0.5*medv
}
score<- function(crim,age,medv) {
score = 0.1*crim+ 0.4*age + 0.5*medv
return(score)
}
score<- function(crim,age,medv) {
score = 0.1*crim+ 0.4*age + 0.5*medv
return(score)
}
score<- function(crim,age,medv) {
score = 0.1*crim+ 0.4*age + 0.5*medv
return(score)
}
scoredata <- as.data.frame(lapply(data, score))
score<- function(crim,age,medv) {
score = 0.1*crim+ 0.4*age + 0.5*medv
return(score)
}
scoredata <- as.data.frame(lapply(data$crim, data$age,data$medv , score))
score<- function(crim,age,medv) {
score = 0.1*crim+ 0.4*age + 0.5*medv
return(score)
}
scoredata <- as.data.frame(lapply(c(data$crim, data$age,data$medv), score))
score<- function(crim,age,medv) {
score = 0.1*crim+ 0.4*age + 0.5*medv
return(score)
}
scoredata <- as.data.frame(lapply(c(data$crim,data$age,data$medv), score))
score<- function(crim,age,medv) {
score = 0.1*crim+ 0.4*age + 0.5*medv
return(score)
}
score_data <-score(data$crim,data$age,data$medv)
score<- function(crim,age,medv) {
score = 0.1*crim+ 0.4*age + 0.5*medv
return(score)
}
score <-score(data$crim,data$age,data$medv)
hist(score)
ratings <- c(Alice = 745, Bob = 456, Carol = 568, Dave = 987, Eve = 473)
ratings <- c(Alice = 745, Bob = 456, Carol = 568, Dave = 987, Eve = 473)
update_elo <- function(R_old, R_opp, S_e, K = 32, C = 5) {
Mu_e <- 1 / (1 + exp(C*(R_old - R_opp)))
R_new <- R_old + K * (S_e - Mu_e)
return(R_new)
}
new_rating <- update_elo(2735, 2463, S_e = 1)
Alice <- update_elo(Alice, Bob, S_e = 1,32, 10)
ratings <- c(Alice = 745, Bob = 456, Carol = 568, Dave = 987, Eve = 473)
Alice <- update_elo(Alice, Bob, S_e = 1,32, 10)
ratings <- update_elo(Alice, Bob, S_e = 1,32, 10)
ratings <- c(Alice = 745, Bob = 456, Carol = 568, Dave = 987, Eve = 473)
Alice = 745
Bob = 456
Carol = 568
Dave = 987
Eve = 473
update_elo <- function(R_old, R_opp, S_e, K, C) {
Mu_e <- 1 / (1 + exp(C*(R_old - R_opp)))
R_new <- R_old + K * (S_e - Mu_e)
return(R_new)
}
Alice <- update_elo(Alice, Bob, S_e = 1,32, 10)
Bob <- update_elo(Bob, Alice, S_e = 0,32, 10)
Carol <- update_elo(Carol, Dave, S_e = 0,32, 10)
Dave <- update_elo(Dave, Carol, S_e = 1,32, 10)
Eve <- update_elo(Eve, Alice, S_e = 0.5 ,32, 10)
Alice <- update_elo(Alice, Eve, S_e = 0.5,32, 10)
Alice <- update_elo(Alice, Bob, S_e = 1,32, 10)
Bob <- update_elo(Bob, Alice, S_e = 0,32, 10)
Carol <- update_elo(Carol, Dave, S_e = 0,32, 10)
Dave <- update_elo(Dave, Carol, S_e = 1,32, 10)
Eve <- update_elo(Eve, Alice, S_e = 0.5 ,32, 10)
Alice <- update_elo(Alice, Eve, S_e = 0.5,32, 10)
ratings <- c(Alice , Bob, Carol, Dave, Eve)
ratings <- c(Alice = 745, Bob = 456, Carol = 568, Dave = 987, Eve = 473)
Alice = 745
Bob = 456
Carol = 568
Dave = 987
Eve = 473
update_elo <- function(R_old, R_opp, S_e, K, C) {
Mu_e <- 1 / (1 + exp(C*(R_old - R_opp)))
R_new <- R_old + K * (S_e - Mu_e)
return(R_new)
}
Alice <- update_elo(Alice, Bob, S_e = 1,32, 10)
Bob <- update_elo(Bob, Alice, S_e = 0,32, 10)
Carol <- update_elo(Carol, Dave, S_e = 0,32, 10)
Dave <- update_elo(Dave, Carol, S_e = 1,32, 10)
Eve <- update_elo(Eve, Alice, S_e = 0.5 ,32, 10)
Alice <- update_elo(Alice, Eve, S_e = 0.5,32, 10)
ratings <- c(Alice , Bob, Carol, Dave, Eve)
hist(ratings)
plot(ratings)
tinytex::reinstall_tinytex(repository = "illinois")
knitr::opts_chunk$set(echo = TRUE,tidy.opts=list(width.cutoff=90), tidy=TRUE, warning = FALSE,message = FALSE)
print(rating)
normalized_data <- transform(data, method = "minmax")
head(normalized_data)
library(liver)
normalized_data <- transform(data, method = "minmax")
head(normalized_data)
score<- function(crim,age,medv) {
score = 0.1*crim+ 0.4*age + 0.5*medv
return(score)
}
score <-score(data$crim,data$age,data$medv)
hist(score, main = "Score Distribution", xlab = "Score", col = "skyblue")
ratings <- c(Alice = 745, Bob = 456, Carol = 568, Dave = 987, Eve = 473)
update_elo <- function(R_old, R_opp, S_e, K = 32, C = 10) {
Mu_e <- 1 / (1 + exp(C*(R_old - R_opp)))
R_new <- R_old + K * (S_e - Mu_e)
return(R_new)
}
ratings["Alice"] <- update_elo(ratings["Alice"], ratings["Bob"], 1)
ratings["Bob"] <- update_elo(ratings["Bob"], ratings["Alice"], 0)
ratings["Carol"] <- update_elo(ratings["Carol"], ratings["Dave"], 0)
ratings["Dave"] <- update_elo(ratings["Dave"], ratings["Carol"], 1)
ratings["Eve"] <- update_elo(ratings["Eve"], ratings["Alice"], 0.5)
ratings["Alice"] <- update_elo(ratings["Alice"], ratings["Eve"], 0.5)
print(round(ratings))
knitr::opts_chunk$set(echo = TRUE,tidy.opts=list(width.cutoff=90), tidy=TRUE, warning = FALSE,message = FALSE)
library(liver)
normalized_data <- transform(data, method = "minmax")
head(normalized_data)
score<- function(crim,age,medv) {
score = 0.1*crim+ 0.4*age + 0.5*medv
return(score)
}
score <-score(data$crim,data$age,data$medv)
hist(score, main = "Score Distribution", xlab = "Score", col = "skyblue")
print(round(ratings))
install.packages(c("cluster", "MASS", "Matrix"))
# Install necessary packages if not already installed
install.packages(c("dplyr", "ggplot2", "sf", "rnaturalearth", "rnaturalearthdata", "rgeos"))
install.packages("tinytex")
# Load libraries
library(dplyr)
library(ggplot2)
library(sf)
install.packages("tidyverse")
# Install necessary packages if not already installed
install.packages(c("dplyr", "ggplot2", "sf", "rnaturalearth", "rnaturalearthdata", "rgeos"))
# Load libraries
library(dplyr)
library(ggplot2)
library(sf)
# Install necessary packages if not already installed
install.packages(c("dplyr", "ggplot2", "sf", "rnaturalearth", "rnaturalearthdata", "rgeos"))
# Load libraries
library(dplyr)
library(ggplot2)
library(sf)
library(dplyr)
library(ggplot2)
library(sf)
install.packages("fs")
library(dplyr)
library(ggplot2)
library(sf)
install.packages("units")
library(dplyr)
library(ggplot2)
library(sf)
library(dplyr)
library(ggplot2)
library(units)
# Install necessary packages if not already installed
install.packages(c("dplyr", "ggplot2", "sf", "rnaturalearth", "rnaturalearthdata", "rgeos"))
# Load libraries
library(dplyr)
library(ggplot2)
library(units)
library(dplyr)
library(ggplot2)
library(sf)
install.packages("units")
# Load libraries
library(dplyr)
library(ggplot2)
library(sf)
library(rnaturalearth)         # Get Canada map
library(rnaturalearthdata)
library(rgeos)
data(iris)
dataset2 <- mutate(iris,
Y = as.numeric(Species == "virginica"))
library(splines)
install.packages("splines")
install.packages("Sleuth2")
data(iris)
library(splines)
library(Sleuth2)
library(tidyverse)
#if a flower is virginica, value = 1
dataset2 <- mutate(iris,
Y = as.numeric(Species == "virginica"))
# Split the data into training and test set
set.seed(1)
row.number <- sample(1:nrow(dataset2), 2/3*nrow(dataset2))
# Separate train and test
train = dataset2[row.number,]
test = dataset2[-row.number,]
probabilities <- model %>% predict(test, type = "response")
model <- glm(Y ~ Petal.Length + Petal.Width, data = train, family = "binomial")
probabilities <- model %>% predict(test, type = "response")
# if prob > 0.5, object is a virginica flower
predicted.classes <- ifelse(probabilities > 0.5, "virginica", "Other")
test['Predicted'] <- predicted.classes
table(test[,-(1:5)])
# Load Canadian provinces shapefile
canada_map <- ne_states(country = "canada", returnclass = "sf")
library(dplyr)
library(ggplot2)
library(sf)
install.packages("sf")
install.packages("rnaturalearth")
install.packages("rnaturalearthdata")
# Predict probabilities
df_clean$Predicted_Prob <- predict(log_model, type = "response")
install.packages("caret")
# Convert 'Percent' into a categorical variable: "High" vs. "Low"
median_percent <- median(df_clean$Percent, na.rm = TRUE)
# Load necessary libraries
library(caret)  # For data preprocessing & evaluation
# Load the dataset
df <- read.csv("C:/Users/felix/Desktop/CODING/felix's works/Mental-Health-On-Suicide-Rates-Trend-Analysis-Prediction/datasets/processed/pivoted_filtered_mental_health.csv")
# ---- 1. Data Preprocessing ----
# Remove missing values
df_clean <- na.omit(df)
# Convert 'Percent' into a categorical variable: "High" vs. "Low"
median_percent <- median(df_clean$Percent, na.rm = TRUE)
df_clean$RiskLevel <- ifelse(df_clean$Percent > median_percent, "High", "Low")
df_clean$RiskLevel <- as.factor(df_clean$RiskLevel)  # Convert to factor
# ---- 2. Train Logistic Regression Model ----
# Train a logistic regression model
log_model <- glm(RiskLevel ~ Year + Age_Group + Gender + Geography,
data = df_clean, family = "binomial")
# Print summary of the model
summary(log_model)
# ---- 3. Model Evaluation ----
# Predict probabilities
df_clean$Predicted_Prob <- predict(log_model, type = "response")
# Convert probabilities to binary predictions (Threshold = 0.5)
df_clean$Predicted_Class <- ifelse(df_clean$Predicted_Prob > 0.5, "High", "Low")
df_clean$Predicted_Class <- as.factor(df_clean$Predicted_Class)
# Create a confusion matrix
conf_matrix <- confusionMatrix(df_clean$Predicted_Class, df_clean$RiskLevel)
# Print confusion matrix
print(conf_matrix)
install.packages("sf")
install.packages("rnaturalearth")
install.packages("rnaturalearthdata")
